{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4l9E63w30A-",
        "outputId": "33edc14f-6fc5-4cf6-cbf6-8211806f38f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for Dataset 1 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Parasitized       0.89      0.82      0.85      2975\n",
            "  Uninfected       0.81      0.88      0.84      2537\n",
            "\n",
            "    accuracy                           0.85      5512\n",
            "   macro avg       0.85      0.85      0.85      5512\n",
            "weighted avg       0.85      0.85      0.85      5512\n",
            "\n",
            "Predictions for Dataset 2 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Parasitized       0.89      0.73      0.80        11\n",
            "  Uninfected       0.67      0.86      0.75         7\n",
            "\n",
            "    accuracy                           0.78        18\n",
            "   macro avg       0.78      0.79      0.77        18\n",
            "weighted avg       0.80      0.78      0.78        18\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Random Forest RF\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn import metrics\n",
        "import joblib\n",
        "import math\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "#Step 1: Load Datasets\n",
        "df = pd.read_csv(\"dataset.csv\")\n",
        "df2 = pd.read_csv(\"dataset3.csv\")\n",
        "\n",
        "#Step 2: Split into training and test data\n",
        "x = df.drop([\"Label\"],axis=1)\n",
        "y = df[\"Label\"]\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=40)\n",
        "\n",
        "x2 = df2.drop([\"Label\"],axis=1)\n",
        "y2 = df2[\"Label\"]\n",
        "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2,y2,test_size=0.2,random_state=40)\n",
        "\n",
        "#Step 3: Build a model of Random Forest\n",
        "model = RandomForestClassifier(n_estimators=10, n_jobs=-1, random_state=101)\n",
        "model.fit(x_train, y_train)\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "model.fit(x_train2, y_train2)\n",
        "y_pred2 = model.predict(x_test2)\n",
        "\n",
        "#Step 4: Make predictions and get classification report\n",
        "print(\"Predictions for Dataset 1 :\")\n",
        "predictions = model.predict(x_test)\n",
        "print(metrics.classification_report(predictions,y_test))\n",
        "\n",
        "print(\"Predictions for Dataset 2 :\")\n",
        "predictions2 = model.predict(x_test2)\n",
        "print(metrics.classification_report(predictions2,y_test2))\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#K Neighbors KNN\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Step 1: Load Dataset\n",
        "df = pd.read_csv(\"dataset.csv\")\n",
        "df2 = pd.read_csv(\"dataset3.csv\")\n",
        "#Step 2: Split into training and test data\n",
        "x = df.drop([\"Label\"],axis=1)\n",
        "y = df[\"Label\"]\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=40)\n",
        "\n",
        "x2 = df2.drop([\"Label\"],axis=1)\n",
        "y2 = df2[\"Label\"]\n",
        "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2,y2,test_size=0.2,random_state=40)\n",
        "\n",
        "#Step 3: Build a model of KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=15)\n",
        "knn.fit(x_train,y_train)\n",
        "y_pred=knn.predict(x_test)\n",
        "\n",
        "knn.fit(x_train2,y_train2)\n",
        "y_pred2=knn.predict(x_test2)\n",
        "#Step 4: Make predictions and get classification report\n",
        "print(\"Predictions for Dataset 1 :\")\n",
        "predictions = knn.predict(x_test)\n",
        "print(metrics.classification_report(predictions,y_test))\n",
        "\n",
        "print(\"Predictions for Dataset 2 :\")\n",
        "predictions2 = knn.predict(x_test2)\n",
        "print(metrics.classification_report(predictions2,y_test2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgVMwoXVDwWR",
        "outputId": "9f273ba5-3208-469c-ab3f-4476d8d3f6e0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for Dataset 1 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Parasitized       0.87      0.92      0.89      2629\n",
            "  Uninfected       0.92      0.88      0.90      2883\n",
            "\n",
            "    accuracy                           0.90      5512\n",
            "   macro avg       0.90      0.90      0.90      5512\n",
            "weighted avg       0.90      0.90      0.90      5512\n",
            "\n",
            "Predictions for Dataset 2 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Parasitized       0.78      0.88      0.82         8\n",
            "  Uninfected       0.89      0.80      0.84        10\n",
            "\n",
            "    accuracy                           0.83        18\n",
            "   macro avg       0.83      0.84      0.83        18\n",
            "weighted avg       0.84      0.83      0.83        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Support Vector Machine SVM\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "\n",
        "#Step 1: Load Dataset\n",
        "df = pd.read_csv(\"dataset.csv\")\n",
        "df2 = pd.read_csv(\"dataset3.csv\")\n",
        "\n",
        "#Step 2: Split into training and test data\n",
        "x = df.drop([\"Label\"],axis=1)\n",
        "y = df[\"Label\"]\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=40)\n",
        "\n",
        "x2 = df2.drop([\"Label\"],axis=1)\n",
        "y2 = df2[\"Label\"]\n",
        "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2,y2,test_size=0.2,random_state=40)\n",
        "\n",
        "#Step 3: Build a model of Support Vector Machine SVM\n",
        "svm =  SVC(kernel=\"rbf\", C=0.025,random_state=101)\n",
        "svm.fit(x_train, y_train)\n",
        "y_pred=svm.predict(x_test)\n",
        "\n",
        "svm.fit(x_train2, y_train2)\n",
        "y_pred2=svm.predict(x_test2)\n",
        "\n",
        "#Step 4: Make predictions and get classification report\n",
        "print(\"Predictions for Dataset 1 :\")\n",
        "predictions = svm.predict(x_test)\n",
        "print(metrics.classification_report(predictions,y_test))\n",
        "\n",
        "print(\"Predictions for Dataset 2 :\")\n",
        "predictions2 = svm.predict(x_test2)\n",
        "print(metrics.classification_report(predictions2,y_test2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Je1SSGbiEdCk",
        "outputId": "3b0a0094-e89c-4d55-d400-bf2f0a6d2a06"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for Dataset 1 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Parasitized       0.90      0.92      0.91      2718\n",
            "  Uninfected       0.92      0.90      0.91      2794\n",
            "\n",
            "    accuracy                           0.91      5512\n",
            "   macro avg       0.91      0.91      0.91      5512\n",
            "weighted avg       0.91      0.91      0.91      5512\n",
            "\n",
            "Predictions for Dataset 2 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Parasitized       0.89      0.89      0.89         9\n",
            "  Uninfected       0.89      0.89      0.89         9\n",
            "\n",
            "    accuracy                           0.89        18\n",
            "   macro avg       0.89      0.89      0.89        18\n",
            "weighted avg       0.89      0.89      0.89        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Naive Bayes NB\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Step 1: Load Dataset\n",
        "df = pd.read_csv(\"dataset.csv\")\n",
        "df2 = pd.read_csv(\"dataset3.csv\")\n",
        "\n",
        "#Step 2: Split into training and test data\n",
        "x = df.drop([\"Label\"],axis=1)\n",
        "y = df[\"Label\"]\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=40)\n",
        "\n",
        "x2 = df2.drop([\"Label\"],axis=1)\n",
        "y2 = df2[\"Label\"]\n",
        "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2,y2,test_size=0.2,random_state=40)\n",
        "\n",
        "#Step 3: Build a model of Gaussian Naive Bayes\n",
        "nb =  GaussianNB()\n",
        "nb.fit(x_train, y_train)\n",
        "y_pred=nb.predict(x_test)\n",
        "\n",
        "nb.fit(x_train2, y_train2)\n",
        "y_pred2=nb.predict(x_test2)\n",
        "\n",
        "#Step 4: Make predictions and get classification report\n",
        "print(\"Predictions for Dataset 1 :\")\n",
        "predictions = nb.predict(x_test)\n",
        "print(metrics.classification_report(predictions,y_test))\n",
        "\n",
        "print(\"Predictions for Dataset 2 :\")\n",
        "predictions2 = nb.predict(x_test2)\n",
        "print(metrics.classification_report(predictions2,y_test2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qor6BbA_ExWu",
        "outputId": "03bcce31-e3b2-4b7a-9cf2-85ed25bafcb0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for Dataset 1 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Parasitized       0.45      0.92      0.61      1364\n",
            "  Uninfected       0.96      0.64      0.76      4148\n",
            "\n",
            "    accuracy                           0.71      5512\n",
            "   macro avg       0.71      0.78      0.69      5512\n",
            "weighted avg       0.83      0.71      0.73      5512\n",
            "\n",
            "Predictions for Dataset 2 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Parasitized       0.56      1.00      0.71         5\n",
            "  Uninfected       1.00      0.69      0.82        13\n",
            "\n",
            "    accuracy                           0.78        18\n",
            "   macro avg       0.78      0.85      0.77        18\n",
            "weighted avg       0.88      0.78      0.79        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision Tree DTree\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Step 1: Load Dataset\n",
        "df = pd.read_csv(\"dataset.csv\")\n",
        "df2 = pd.read_csv(\"dataset3.csv\")\n",
        "\n",
        "#Step 2: Split into training and test data\n",
        "x = df.drop([\"Label\"],axis=1)\n",
        "y = df[\"Label\"]\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=40)\n",
        "\n",
        "x2 = df2.drop([\"Label\"],axis=1)\n",
        "y2 = df2[\"Label\"]\n",
        "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2,y2,test_size=0.2,random_state=40)\n",
        "\n",
        "#Step 3: Build a model of Decision Tree\n",
        "dtree = DecisionTreeClassifier(max_depth=10, random_state=101, max_features = None, min_samples_leaf = 15)\n",
        "dtree.fit(x_train, y_train)\n",
        "y_pred=dtree.predict(x_test)\n",
        "\n",
        "dtree.fit(x_train2, y_train2)\n",
        "y_pred2=dtree.predict(x_test2)\n",
        "\n",
        "#Step 4: Make predictions and get classification report\n",
        "print(\"Predictions for Dataset 1 :\")\n",
        "predictions = dtree.predict(x_test)\n",
        "print(metrics.classification_report(predictions,y_test))\n",
        "\n",
        "print(\"Predictions for Dataset 2 :\")\n",
        "predictions2 = dtree.predict(x_test2)\n",
        "print(metrics.classification_report(predictions2,y_test2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vvq5OT_GE9YQ",
        "outputId": "39e4a826-8521-409a-c214-1423a33bb78c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for Dataset 1 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Parasitized       0.87      0.92      0.89      2611\n",
            "  Uninfected       0.92      0.88      0.90      2901\n",
            "\n",
            "    accuracy                           0.90      5512\n",
            "   macro avg       0.90      0.90      0.90      5512\n",
            "weighted avg       0.90      0.90      0.90      5512\n",
            "\n",
            "Predictions for Dataset 2 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Parasitized       0.78      0.88      0.82         8\n",
            "  Uninfected       0.89      0.80      0.84        10\n",
            "\n",
            "    accuracy                           0.83        18\n",
            "   macro avg       0.83      0.84      0.83        18\n",
            "weighted avg       0.84      0.83      0.83        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic Regression LR\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Step 1: Load Dataset\n",
        "df = pd.read_csv(\"dataset.csv\")\n",
        "df2 = pd.read_csv(\"dataset3.csv\")\n",
        "\n",
        "#Step 2: Split into training and test data\n",
        "x = df.drop([\"Label\"],axis=1)\n",
        "y = df[\"Label\"]\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=40)\n",
        "\n",
        "x2 = df2.drop([\"Label\"],axis=1)\n",
        "y2 = df2[\"Label\"]\n",
        "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2,y2,test_size=0.2,random_state=40)\n",
        "\n",
        "#Step 3: Build a model of Logistic Regression LR\n",
        "lr =  LogisticRegression()\n",
        "lr.fit(x_train, y_train)\n",
        "y_pred=lr.predict(x_test)\n",
        "\n",
        "lr.fit(x_train2, y_train2)\n",
        "y_pred2=lr.predict(x_test2)\n",
        "\n",
        "#Step 4: Make predictions and get classification report\n",
        "print(\"Predictions for Dataset 1 :\")\n",
        "predictions = lr.predict(x_test)\n",
        "print(metrics.classification_report(predictions,y_test))\n",
        "\n",
        "print(\"Predictions for Dataset 2 :\")\n",
        "predictions2 = lr.predict(x_test2)\n",
        "print(metrics.classification_report(predictions2,y_test2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta_DBQtsgqM3",
        "outputId": "8bca985c-9fcd-4579-e796-2dbe745585d4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for Dataset 1 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Parasitized       0.90      0.92      0.91      2710\n",
            "  Uninfected       0.92      0.90      0.91      2802\n",
            "\n",
            "    accuracy                           0.91      5512\n",
            "   macro avg       0.91      0.91      0.91      5512\n",
            "weighted avg       0.91      0.91      0.91      5512\n",
            "\n",
            "Predictions for Dataset 2 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Parasitized       0.89      0.89      0.89         9\n",
            "  Uninfected       0.89      0.89      0.89         9\n",
            "\n",
            "    accuracy                           0.89        18\n",
            "   macro avg       0.89      0.89      0.89        18\n",
            "weighted avg       0.89      0.89      0.89        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(model.score(x_test2,y_test2))"
      ],
      "metadata": {
        "id": "1etBkN5Zwp4v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}